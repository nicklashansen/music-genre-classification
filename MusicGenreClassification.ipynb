{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:red\">WORK IN PROGRESS</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classification\n",
    "### 02452 - Audio Information Processing Systems\n",
    "\n",
    "#### Bragi Marinosson (s185510) & Nicklas Hansen (s153077)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code and results for the exam project on Music Genre Classification for the 02452 graduate course offered at the Technical University of Denmark (DTU). Work has been equally distributed between the two authors and any questions can be directed at either of us.\n",
    "\n",
    "The work presented in this notebook is to be considered open source under the MIT License. If you found this code useful in your research, then please cite\n",
    "\n",
    "\n",
    "```\n",
    "@inproceedings{mgc-marinosson-hansen,\n",
    "  title={Music Genre Classification},\n",
    "  author={Hansen, Nicklas and Marinosson, Bragi},\n",
    "  year={2019}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw, high-quality MP3-encoded audio data (30 s per sample) and genre classifications from the Free Music Archive (FMA) dataset is used in this study. For more information on the dataset, visit https://github.com/mdeff/fma/ and/or read the paper *FMA: A Dataset For Music Analysis*, MichaÃ«l Defferrard, Kirell Benzi, Pierre Vandergheynst, Xavier Bresson (2017).\n",
    "\n",
    "As the original dataset contains 105 GB of audio data, we do not make that data available directly. To get your hands on the raw data, refer to the aforementioned website and paper. The original dataset is required in order to run the preprocessing steps in this code. Optionally, you can skip this step by setting the ``PREPROCESS`` global parameter to ``False`` and instead downloading our preprocessed data, which only takes up roughly 2 GB and saves you a lot of time. The preprocessed data is made available at the following link:\n",
    "\n",
    "https://1drv.ms/u/s!AnqePMbr4kj8nvA7HBGWzBJIvOB-9w\n",
    "\n",
    "Please note that we cannot guarantee the availability of this data indefinitely. Therefore, you may have to rerun the preprocessing step yourself in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup\n",
    "\n",
    "All code was developed and tested on Windows 10 (version 10.0.17134) with Python 3.7 and has been verified to work both with and without a GPU, although it is highly recommended to use one during training of neural networks as it decreases wall time significantly. For this study, a GTX1080 unit was used on a computer with 16 GB RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports\n",
    "\n",
    "Required dependencies are listed as imports below. If you intend to run this code on your own machine, please make sure that you have installed all of the below dependencies before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickl\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pickle\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection, neighbors, metrics\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import librosa\n",
    "from librosa import display\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, RNN, LSTM\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import softmax, relu\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working directory as data path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to set this path to the root of the dataset, keeping all folders as is, but removing files in the root directory that are not MP3 files as the code does not check for this (resulting in less operations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/FMA/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path to additional files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to set this path to a location that either contains files related to this code or a location in which you want to store such files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRES = 'C:/Users/nickl/OneDrive/DTU_2019/Audio Information Processing Systems/Music Genre Classification/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set global seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = int(0x02452)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``PREPROCESS`` determines whether the code should redo the preprocessing step or not. If you already preprocessed the original data or downloaded our preprocessed files, you can set ``PREPROCESS`` to ``False`` for a significant speed-up. Otherwise, you will have to complete the preprocessing step.\n",
    "\n",
    "``NUM_CLASSES`` determines the number of genres to be used for classification. In this study we use 10 classes, but in principle this could be any number of classes (up to the number of genres in the dataset). Aside from the discarded classes as noted in the ``load_tracklist`` function, the classes used are selected based on the number of available samples (favoring a high count).\n",
    "\n",
    "``NUM_FRAMES`` determines the number of frames used in each audio segment. Due to a window size of 2048 and a hop length of 1024, we require 128 frames to represent 3 seconds of audio as used in our study.\n",
    "\n",
    "``MFCC_COEFFICIENTS`` determines the number of MFCC coefficients (frequency bands) to be used to model the Mel-frequency spectrum of the audio signal. A high number of coefficents produces a good frequency resolution but also requires proportionally more space and computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESS = False\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "NUM_FRAMES = 128\n",
    "MFCC_COEFFICIENTS = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all available files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data(target_file='train'):\n",
    "    '''\n",
    "    Loads any data from target location.\n",
    "    '''\n",
    "    with open(GENRES + target_file + '.pickle', 'rb') as handle:\n",
    "        return pickle.load(handle)\n",
    "    \n",
    "    \n",
    "def save_data(data, target_file='train'):\n",
    "    '''\n",
    "    Saves any data to target location.\n",
    "    '''\n",
    "    with open(GENRES + target_file + '.pickle', 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "\n",
    "def load_tracklist(discarded_genres=['Experimental', 'International', 'Instrumental', 'Old-Time / Historic', 'Spoken']):\n",
    "    '''\n",
    "    Load list of tracks with genre information as data frame.\n",
    "    '''\n",
    "    tracklist = pd.read_csv(GENRES + 'genres.csv').set_index('id', drop=True)\n",
    "    \n",
    "    tracklist = tracklist[tracklist.genre.notnull()]\n",
    "    for genre in discarded_genres:\n",
    "        tracklist = tracklist[tracklist.genre != genre]\n",
    "\n",
    "    return tracklist\n",
    "\n",
    "\n",
    "def get_file_list(verbose=False):\n",
    "    '''\n",
    "    Returns a list of all .h5 files in current working directory.\n",
    "    '''\n",
    "    files = []\n",
    "    for r, d, f in os.walk(os.getcwd()):\n",
    "        for file in f:\n",
    "            if '.mp3' in file:\n",
    "                files.append(os.path.join(r, file))\n",
    "\n",
    "    print(f'Found {len(files)} files!')\n",
    "    return files\n",
    "\n",
    "\n",
    "def train_test_split(files, test_num=None, p=None):\n",
    "    '''\n",
    "    Returns two lists (train and test). If test_num is\n",
    "    not None, the second list will contain test_num number\n",
    "    of elements and the first list contains the remainder.\n",
    "    If p is not None, lists are populated such that the first\n",
    "    list contains elements selected with p probability\n",
    "    and the second list contains elements selected with\n",
    "    1-p probability (at random).\n",
    "    '''\n",
    "    if test_num is not None:\n",
    "        return files[:-test_num], files[-test_num:]\n",
    "    \n",
    "    elif p is not None:\n",
    "        lsts = [], []\n",
    "        for file in files:\n",
    "            a = np.random.choice(2, 1, p=[p, 1-p])[0]\n",
    "            lsts[a].append(file)\n",
    "        return lsts\n",
    "    \n",
    "    raise ParameterError('Either test_num or p must have a value!')\n",
    "\n",
    "    \n",
    "def id_from_filename(file):\n",
    "    return str(int(file.split('\\\\')[-1].split('.')[0]))\n",
    "    \n",
    "\n",
    "def get_top_genres(genre_dict):\n",
    "    '''\n",
    "    Returns the top occurring genres as a list.\n",
    "    '''\n",
    "    lst = sorted(genre_dict, key=genre_dict.get, reverse=True)\n",
    "    return lst[:NUM_CLASSES] if len(lst) > NUM_CLASSES else lst\n",
    "    \n",
    "    \n",
    "def files_with_available_genre(files, predefined_tracklist=None, genre_cap=None, return_genre_count=False, verbose=False):\n",
    "    \n",
    "    lst, genres, tracklist = [], defaultdict(int), load_tracklist()\n",
    "\n",
    "    for file in files:\n",
    "        idx = id_from_filename(file)\n",
    "        \n",
    "        try:\n",
    "            g = tracklist.loc[idx].genre\n",
    "            \n",
    "            if genre_cap is not None and genres[g] >= 1000:\n",
    "                continue\n",
    "                \n",
    "            if (predefined_tracklist is None or g in predefined_tracklist):\n",
    "                lst.append(file)\n",
    "                genres[g] += 1\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if predefined_tracklist is None:\n",
    "        print(f'Found {len(lst)} files with labels!')\n",
    "    else:\n",
    "        print(f'Found {len(lst)} files with labels among top {NUM_CLASSES} genres!')\n",
    "    \n",
    "    if return_genre_count is True:\n",
    "        return lst, get_top_genres(genres), genres\n",
    "    \n",
    "    return lst, get_top_genres(genres)\n",
    "\n",
    "\n",
    "if PREPROCESS is True:\n",
    "    files, genres = files_with_available_genre(get_file_list(verbose=True), verbose=True)\n",
    "    files, genres, genre_count = files_with_available_genre(shuffle(files), genres, genre_cap=1000, return_genre_count=True, verbose=True)\n",
    "    \n",
    "    train_files, test_files = train_test_split(files, p=0.9)\n",
    "    class_weights = np.array([1/(genre_count[g]/(len(files)/NUM_CLASSES)) for g in genres])\n",
    "\n",
    "    save_data((genres, class_weights), 'class_weights')\n",
    "    \n",
    "    print('\\nTrain files:', len(train_files), '\\nTest  files:', len(test_files), '\\n\\nClasses and class weights:')\n",
    "    print(genres)\n",
    "    print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def mfcc_from_file(file, n_mfcc=MFCC_COEFFICIENTS):\n",
    "    '''\n",
    "    Computes MFCC coefficients of an audio file.\n",
    "    '''\n",
    "    x, sr = librosa.load(file, sr=None)\n",
    "    return librosa.feature.mfcc(x, sr, n_mfcc=n_mfcc, n_fft=2048, hop_length=1024)\n",
    "\n",
    "\n",
    "def generate_data(files, genres, target_file='train', skip_factor=1):\n",
    "    '''\n",
    "    Generates features and labels from from a sequence\n",
    "    of filenames and stores the resulting data as a\n",
    "    pickle object on the specified path.\n",
    "    '''\n",
    "    tracklist = load_tracklist()\n",
    "    X, y = [], []\n",
    "    \n",
    "    for file_num, file in enumerate(files):\n",
    "        try:\n",
    "            mfccs = np.transpose(mfcc_from_file(file))\n",
    "            idx, lbl = 0, tracklist.loc[id_from_filename(file)].genre\n",
    "            while idx < mfccs.shape[0] - NUM_FRAMES:\n",
    "                X.append(mfccs[idx:idx+NUM_FRAMES])\n",
    "                y.append(genres.index(lbl))\n",
    "                idx += NUM_FRAMES*skip_factor\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        sys.stdout.write(f'\\rGenerating {target_file} data: {int((file_num+1)*100/len(files))}% ({file_num+1})')\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    save_data((X,y), target_file)\n",
    "    print()\n",
    "      \n",
    "    \n",
    "if PREPROCESS is True:\n",
    "    generate_data(train_files, genres, target_file='train')\n",
    "    generate_data(test_files, genres, target_file='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 61829 sequences from train file.\n",
      "Loaded 7152 sequences from test file.\n",
      "Loaded 10 classes and weights.\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_data('train')\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "print(f'Loaded {len(y_train)} sequences from train file.')\n",
    "\n",
    "X_test, y_test = load_data('test')\n",
    "print(f'Loaded {len(y_test)} sequences from test file.')\n",
    "\n",
    "genres, class_weights = load_data('class_weights')\n",
    "print(f'Loaded {len(genres)} classes and weights.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_mfcc(x_mfcc, y):\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    librosa.display.specshow(np.transpose(x_mfcc))\n",
    "    plt.colorbar()\n",
    "    plt.title(f'MFCC ({y})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_mfcc(X_train[0], genres[y_train[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the traditional KNN classifier as a performance baseline. Because prediction time scales linearly with the number of dimensions, it is necessary to transform the features to a smaller dimensional space before feeding it into the classifier. We have chosen to use the sum of each frequency band across all timesteps as our transformation. This transformation completely discards the temporal information that we have available but that should be considered a limitation of the traditional KNN classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature transform for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_knn_train = np.array([np.sum(x, axis=0) for x in X_train])\n",
    "y_knn_train = y_train\n",
    "\n",
    "X_knn_test = np.array([np.sum(x, axis=0) for x in X_test])\n",
    "y_knn_test = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 44%\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.39      0.60      0.47      1045\n",
      "          1       0.40      0.55      0.46       958\n",
      "          2       0.43      0.38      0.40      1040\n",
      "          3       0.38      0.33      0.35       964\n",
      "          4       0.77      0.78      0.78      1203\n",
      "          5       0.31      0.17      0.22       952\n",
      "          6       0.26      0.19      0.22       570\n",
      "          7       0.40      0.43      0.42       150\n",
      "          8       0.34      0.20      0.25       170\n",
      "          9       0.42      0.22      0.29       100\n",
      "\n",
      "avg / total       0.44      0.45      0.43      7152\n",
      "\n",
      "0: Rock\n",
      "1: Hip-Hop\n",
      "2: Folk\n",
      "3: Electronic\n",
      "4: Classical\n",
      "5: Pop\n",
      "6: Jazz\n",
      "7: Country\n",
      "8: Soul-RnB\n",
      "9: Blues\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_knn_train, y_knn_train)\n",
    "\n",
    "y_pred = knn.predict(X_knn_test)\n",
    "print('Accuracy:', str(int(metrics.accuracy_score(y_knn_test, y_pred)*100)) + '%\\n')\n",
    "print(metrics.classification_report(y_knn_test, y_pred))\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'{i}: {genres[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve classification performance, we choose to model the problem using a neural architecture. More specifically, we construct a deep convolutional neural network using 2D convolution, treating the MFCC features as an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA has been disabled.\n"
     ]
    }
   ],
   "source": [
    "WEIGHTED_LOSS = True # Weight loss based on class distribution\n",
    "\n",
    "BATCH_SIZE = 256 # Hardware-dependent\n",
    "CUDA = torch.cuda.is_available() # Check if we have a GPU available\n",
    "\n",
    "print('CUDA has been enabled.' if CUDA else 'CUDA has been disabled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated (217, 24, 27) batches for training, validation and test.\n"
     ]
    }
   ],
   "source": [
    "def convert_to_batches(data, is_y = False):\n",
    "    '''\n",
    "    Converts a list of numpy arrays to a list of\n",
    "    batched numpy arrays of size BATCH_SIZE.\n",
    "    '''\n",
    "    batches, i = [], 0\n",
    "\n",
    "    while i < len(data)-BATCH_SIZE:\n",
    "        arr = data[i:i+BATCH_SIZE] if is_y is False else data[i:i+BATCH_SIZE]\n",
    "        var = Variable(torch.from_numpy(np.array(arr)).float())\n",
    "        if CUDA is True:\n",
    "            var = var.cuda()\n",
    "        batches.append(var)\n",
    "        i += BATCH_SIZE\n",
    "        \n",
    "    return batches\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X_train, y_train, test_size=0.1)\n",
    "\n",
    "X_train, X_val, X_test = convert_to_batches(X_train), convert_to_batches(X_val), convert_to_batches(X_test)\n",
    "y_train, y_val, y_test = convert_to_batches(y_train, is_y=True), convert_to_batches(y_val, is_y=True), convert_to_batches(y_test, is_y=True)\n",
    "\n",
    "print(f'Generated ({len(y_train)}, {len(y_val)}, {len(y_test)}) batches for training, validation and test.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (a): ReLU()\n",
      "  (rnn): LSTM(32, 128, batch_first=True)\n",
      "  (lin): Linear(in_features=16384, out_features=1448, bias=True)\n",
      "  (out): Linear(in_features=1448, out_features=10, bias=True)\n",
      "  (softmax): Softmax()\n",
      ") \n",
      "\n",
      "Successfully passed data through network.\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "    \n",
    "        self.a = nn.ReLU()    \n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        self.rnn = LSTM(input_size=MFCC_COEFFICIENTS, hidden_size=NUM_FRAMES, num_layers=1, batch_first=True)        \n",
    "        self.lin = nn.Linear(NUM_FRAMES**2, int(NUM_FRAMES**1.5))\n",
    "        self.out = nn.Linear(int(NUM_FRAMES**1.5), NUM_CLASSES)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    \n",
    "    def init_hidden(self):\n",
    "        h = Variable(torch.zeros(1, BATCH_SIZE, NUM_FRAMES))\n",
    "        c = Variable(torch.zeros(1, BATCH_SIZE, NUM_FRAMES))\n",
    "        \n",
    "        if CUDA:\n",
    "            h = h.cuda()\n",
    "            c = c.cuda()\n",
    "        \n",
    "        return h, c\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # (batch, frames, features)\n",
    "        x, _ = self.rnn(x, self.hidden)\n",
    "        x = x.contiguous().view(-1, NUM_FRAMES**2)\n",
    "        \n",
    "        # (batch, units)\n",
    "        x = self.a(self.lin(x))\n",
    "        return self.softmax(self.out(x))\n",
    "    \n",
    "\n",
    "net = Net()\n",
    "print(net, '\\n')\n",
    "\n",
    "try:\n",
    "    out = net(X_train[0])\n",
    "    print('Successfully passed data through network.')\n",
    "except Exception as e:\n",
    "    print('An error occurred while passing data through network:\\n' + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-3ee980d24923>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_accs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m \u001b[0mtrain_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-3ee980d24923>\u001b[0m in \u001b[0;36mtrain_net\u001b[1;34m(net, epochs, lr, verbose)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0maccs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-3ee980d24923>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(net, X, y, optimize)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;31m# For each batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0mtemp_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtemp_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mepoch_acc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-3ee980d24923>\u001b[0m in \u001b[0;36mrun_batch\u001b[1;34m(X, y, epoch_loss, epoch_acc)\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mbatch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \"\"\"\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def accuracy(out, y):\n",
    "    '''\n",
    "    Calculate accuracy of model where\n",
    "    out.shape = (batches, classes) and y.shape = (batches)\n",
    "    '''\n",
    "    out = torch.max(out, 1)[1].float()\n",
    "    eq = torch.eq(out, y.float()).float()\n",
    "    return torch.mean(eq)\n",
    "\n",
    "\n",
    "def train_net(net, epochs=10, lr=1e-3, verbose=True):\n",
    "\n",
    "    # Move network to GPU if available\n",
    "    if CUDA:\n",
    "        net.cuda()\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=lr/100)\n",
    "    losses, accs, val_losses, val_accs = [], [], [], []\n",
    "    \n",
    "    if verbose:\n",
    "        start_time = time.time()\n",
    "    \n",
    "    def plot(losses, accs, val_losses, val_accs):\n",
    "        '''\n",
    "        Continously plots the training/validation loss and accuracy\n",
    "        of the model being trained. This functions is only called if\n",
    "        verbose is True for the training session.\n",
    "        '''\n",
    "        e = [i for i in range(len(losses))]\n",
    "        fig = plt.figure(figsize=(12,4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(e, losses, label='Loss (Training)')\n",
    "        \n",
    "        plt.plot(e, val_losses, label='Loss (Validation)')\n",
    "            \n",
    "        plt.legend()\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(e, accs, label='Accuracy (Training)')\n",
    "        \n",
    "        plt.plot(e, val_accs, label='Accuracy (Validation)')\n",
    "            \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    def run(net, X, y, optimize = False):\n",
    "        '''\n",
    "        This function constitutes a single epoch.\n",
    "        If optimize is True, the associated optimizer will backpropagate\n",
    "        and adjust network weights.\n",
    "        Returns the average sample loss and accuracy for that epoch.\n",
    "        '''\n",
    "        epoch_loss, epoch_acc = 0, []\n",
    "        \n",
    "        if len(X) == 0 or len(y) == 0:\n",
    "            raise ValueError('Something went wrong. Invalid input!')\n",
    "        \n",
    "        # Helper function responsible for running a batch\n",
    "        def run_batch(X, y, epoch_loss, epoch_acc):\n",
    "\n",
    "            y = y.long()\n",
    "\n",
    "            if CUDA:\n",
    "                X = X.cuda()\n",
    "                y = y.cuda()\n",
    "\n",
    "            out = net(X)\n",
    "\n",
    "            # Compute loss and accuracy for batch\n",
    "            batch_loss = criterion(out, y)\n",
    "            batch_acc = accuracy(out, y)\n",
    "\n",
    "            # If training session, initiate backpropagation and optimization\n",
    "            if optimize == True:\n",
    "                optimizer.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if CUDA:\n",
    "                batch_acc = batch_acc.cpu()\n",
    "                batch_loss = batch_loss.cpu()\n",
    "\n",
    "            # Accumulate loss and accuracy for epoch metrics\n",
    "            epoch_loss += batch_loss.data.numpy() / float(BATCH_SIZE)\n",
    "            epoch_acc.append(batch_acc.data.numpy())\n",
    "\n",
    "            return epoch_loss, epoch_acc\n",
    "\n",
    "        # For each batch\n",
    "        for i,x in enumerate(X):\n",
    "            temp_loss, temp_acc = run_batch(x, y[i], epoch_loss, epoch_acc)\n",
    "            epoch_loss += temp_loss / float(len(X))\n",
    "            epoch_acc.append(np.mean(temp_acc))\n",
    "\n",
    "        return epoch_loss, np.mean(epoch_acc)\n",
    "    \n",
    "    \n",
    "    # Iterate over training epochs\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        net.train()\n",
    "        loss, acc = run(net, X_train, y_train, optimize=True)\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "        \n",
    "        net.eval()\n",
    "        val_loss, val_acc = run(net, X_test, y_test)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        # Optionally plot performance metrics continously\n",
    "        if verbose:\n",
    "            \n",
    "            # Print measured wall-time of first epoch\n",
    "            if epoch == 0:\n",
    "                dur = str(int((time.time() - start_time)/60))\n",
    "                print(f'\\nEpoch wall-time: {dur} min')\n",
    "                \n",
    "            plot(losses, accs, val_losses, val_accs)\n",
    "    \n",
    "train_net(net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
